# -*- coding: utf-8 -*-
"""FRAUD DETECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14yKp9ylYa7kojlR-l82bIx8spCcnqrdu

#TITLE : Credit Card Fraud Detection
*   AUTHOR: Arman Shaikh
*   DOMAIN: DATA SCIENCE
*   AIM   : To build a ML model to identify fraudulent transactions

IMPORT REQUIRED LIBRARIES
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

"""LOAD AND EXPLORE THE DATESET

"""

# Load the dataset
df = pd.read_csv('/content/creditcard.csv')

# Display the first few rows of the dataset
print(df.head())

# Display basic information about the dataset
print(df.info())

# Check for missing values
print(df.isnull().sum())

"""DATA PREPROCESSING"""

# Separate features and target variable
X = df.drop('Class', axis=1)
y = df['Class']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""TRAIN THE MODEL"""

# Initialize the Random Forest Classifier
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Initialize an imputer to replace missing values with the mean of each column
imputer = SimpleImputer(strategy='mean')

# Fit the imputer on the training data and transform both training and testing data
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Initialize an imputer to replace missing values with the most frequent value for the target variable
imputer_y = SimpleImputer(strategy='most_frequent')

# Fit and transform the target variable (y_train)
y_train = imputer_y.fit_transform(y_train.values.reshape(-1, 1))
y_train = y_train.ravel()

# Now you can train the model
model.fit(X_train, y_train)

"""MODEL EVALUATION"""

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nAccuracy Score:", accuracy_score(y_test, y_pred))

"""**Explanation**
* Import Libraries: We import the necessary libraries for data manipulation, model training, and evaluation.

* Load and Explore the Dataset: Load the dataset and explore its structure, checking for any missing values.

* Data Preprocessing: Split the dataset into features (X) and target (y). The target variable (Class) indicates whether a transaction is fraudulent (1) or not (0). We also split the data into training and testing sets to evaluate the model's performance.

* Train the Model: We use a Random Forest Classifier to train the model. This is a popular choice for classification tasks due to its robustness and ability to handle imbalanced datasets.

* Evaluate the Model: After training, we evaluate the model using the test set. We use the confusion matrix, classification report, and accuracy score to understand how well the model performs in identifying fraudulent transactions.
"""